{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_gym\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import make_env\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.sac.policies import MlpPolicy as SACPolicy\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.a2c.policies import MlpPolicy as A2CPolicy\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo.policies import MlpPolicy as PPOPolicy\n",
    "\n",
    "from sb3_contrib import ARS\n",
    "from sb3_contrib.ars.policies import ARSPolicy\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from sb3_contrib.ppo_recurrent.policies import RecurrentActorCriticPolicy\n",
    "\n",
    "from sb3_contrib import TQC\n",
    "from sb3_contrib.tqc.policies import MlpPolicy as TQCPolicy\n",
    "\n",
    "from sb3_contrib import TRPO\n",
    "from sb3_contrib.trpo.policies import MlpPolicy as TRPOPolicy\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 256\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_algo(algo_name):\n",
    "    if algo_name == 'PPO':\n",
    "        return PPO\n",
    "\n",
    "    if algo_name == 'A2C':\n",
    "        return A2C\n",
    "\n",
    "    if algo_name == 'TRPO':\n",
    "        return TRPO\n",
    "\n",
    "\n",
    "def run_evals(env_name, algo_name, name, n_eval_episodes, env_seed=42):\n",
    "    save_path = f'./data/{env_name}/{algo_name}/{name}/'\n",
    "\n",
    "    env = make_env(env_name, env_seed=env_seed)\n",
    "    algo = get_algo(algo_name)\n",
    "    model = algo.load(save_path + 'best_model', env=env)\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    df_names = ['D', 'X', 'R', 'P', 'Y']\n",
    "\n",
    "    for episode in tqdm(range(n_eval_episodes)):\n",
    "        for timestep in range(env.num_periods):\n",
    "            action = model.predict(obs)\n",
    "            obs, reward, _, _ = env.step(action[0])\n",
    "\n",
    "        # Done with the episode so now add the data their lists\n",
    "\n",
    "        for df_name in df_names:\n",
    "            df = getattr(env, df_name)\n",
    "\n",
    "            if not os.path.exists(save_path + f'eval/{episode}/'):\n",
    "                os.makedirs(save_path + f'eval/{episode}/')\n",
    "\n",
    "            df.to_csv(save_path + f'eval/{episode}/{df_name}.csv')\n",
    "\n",
    "        # Reset the env for the next episode and select a new seed\n",
    "\n",
    "        obs = env.reset()\n",
    "        env.seed_int = episode\n",
    "\n",
    "\n",
    "run_evals('NetworkManagement-v1-100', 'TRPO', 'default', 10)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 10:44:50) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
